{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oETEJaMrZY6I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_df = pd.read_csv(r'/content/dataset - cleaned_hm.csv')\n",
        "data_df.head()\n",
        "data = data_df"
      ],
      "metadata": {
        "id": "QjbmU4lKZjFX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows =  data.loc[data['num_sentence'] > 10]\n",
        "mod_data = rows[\"cleaned_hm\"].to_list()\n",
        "mod_data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "P3bynaQPZjH-",
        "outputId": "ae8bdfab-a1ea-46e4-9b85-777e46eefe29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sunset is the time when the sun goes down and night begins. During the sunset, nature assumes fresh, bright, and charming. The sun seems to be a disc of gold. At the time of sunset, one can enjoy the serenity of a sunset. Then nature seems in a hurry. People finish their work and return home. Birds return to their nests. The cowboys become busy with returning home with cattle. When the sun sets, nature looks very beautiful. Then the nature starts getting dark. The slight darkness of the sunset creates a feeling of joy and tranquility in us. The beauty of the sunset helps a poet to generate any ideas and compose poems.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY7gVka1ZjLG",
        "outputId": "907a1ea7-c5be-42cb-d555-6fa2c9e2a9a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "punctuation_set = set(string.punctuation)\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    words = [word for word in words if word not in punctuation_set]\n",
        "\n",
        "    processed_sentence = ' '.join(words)\n",
        "    return processed_sentence\n",
        "\n",
        "def preprocess_data(data):\n",
        "    processed_data = []\n",
        "    for paragraph in data:\n",
        "\n",
        "        sentences = sent_tokenize(paragraph)\n",
        "\n",
        "        processed_sentences = [preprocess_sentence(sentence) for sentence in sentences]\n",
        "\n",
        "        processed_data.extend(processed_sentences)\n",
        "    return processed_data\n",
        "\n",
        "processed_data = preprocess_data(mod_data)\n",
        "print(processed_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ULwQscxZjTn",
        "outputId": "39f32cb1-58af-4b48-9fda-a1598bfa791c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the second essay in a two-part series about my journey to visit the Taj Mahal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART A"
      ],
      "metadata": {
        "id": "BNXWS9YHZ0nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "from collections import defaultdict\n",
        "\n",
        "tokenized_dataset = [sentence.split() for sentence in processed_data]\n",
        "\n",
        "model = Word2Vec(sentences=tokenized_dataset, min_count=1, vector_size=100, window=5)\n",
        "\n",
        "def predict_context(model, word):\n",
        "    return model.wv.most_similar(word)\n",
        "\n",
        "word_to_predict = \"someone\"\n",
        "similar_words = predict_context(model, word_to_predict)\n",
        "similar_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWVH5YkzZjWm",
        "outputId": "7d483868-cae7-45d2-eaa9-1670ce4b1a6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('or', 0.9989322423934937),\n",
              " ('its', 0.998910129070282),\n",
              " ('all', 0.9989023208618164),\n",
              " ('when', 0.9989014863967896),\n",
              " ('us', 0.998879611492157),\n",
              " ('from', 0.9988564848899841),\n",
              " ('He', 0.9988465905189514),\n",
              " ('were', 0.9988460540771484),\n",
              " ('who', 0.9988430738449097),\n",
              " ('after', 0.9988406896591187)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(processed_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRq0KH0PZjZ-",
        "outputId": "1fdecaa4-5039-47f3-ff5e-7db2ff06c503"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4475"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART B"
      ],
      "metadata": {
        "id": "Pizhthw1ZxZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(processed_data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "input_sequences = []\n",
        "for line in data:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Create predictors and labels\n",
        "X, y = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# Define the model\n",
        "embedding_dim = 50\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, embedding_dim, input_length=max_sequence_len-1))\n",
        "model.add(SimpleRNN(100))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=3)\n",
        "model.fit(X, y, epochs=50, verbose=1, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mILnTna_ZjdW",
        "outputId": "054c71ad-956d-4e0d-993a-3b5e333fa57d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 8.6080 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8.6000 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 8.5917 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.5833 - accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 8.5746 - accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.5656 - accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 8.5561 - accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 8.5461 - accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 8.5354 - accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8.5240 - accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.5118 - accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.4986 - accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.4844 - accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.4691 - accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8.4525 - accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.4346 - accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8.4152 - accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.3943 - accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8.3717 - accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 8.3473 - accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 8.3210 - accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 8.2926 - accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 8.2621 - accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 8.2292 - accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.1938 - accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 8.1558 - accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 8.1150 - accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.0712 - accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8.0243 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 7.9740 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 7.9202 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.8626 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.8011 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 7.7355 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.6655 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.5909 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 7.5115 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 7.4272 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.3375 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.2423 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 7.1415 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 7.0346 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.9215 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.8020 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 6.6757 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.5425 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.4021 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.2543 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.0988 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 5.9354 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e1e96dd7f40>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate next and previous words\n",
        "def generate_next_and_prev_word(seed_text):\n",
        "    for _ in range(2): # Predict both next and previous word\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        print(token_list)\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Example usage\n",
        "seed_text = \"Taj\"\n",
        "predicted_text = generate_next_and_prev_word(seed_text)\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz_iXIjBZjj1",
        "outputId": "1177e78e-079e-4a64-ab70-5e19cf2237e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[271]\n",
            "1/1 [==============================] - 0s 255ms/step\n",
            "[271, 1716]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Taj period truth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cfxEfpa6ZjnF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OAWY7JuxZjqG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V3u1vNz5Zjtg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gzvB4rfsZjwd"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}